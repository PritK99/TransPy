# Transformers-from-Scratch

## Table of Contents

- [Project](#Transformers-from-Scratch)
  - [Table of Contents](#table-of-contents)
  - [About The Project](#about-the-project)
  - [Demo](#demo)
  - [File Structure](#file-structure)
  - [Contributors](#contributors)
  - [References](#references)
  - [License](#license)
  

## About

Building a custom Transformer model from scratch in PyTorch for English-to-Spanish translation.

<img src = "./assets/Transformer-architecture.png" alt="The Architecture of Transformer Model">

## File Structure
```
👨‍💻Transformers-from-Scratch
 ┣ 📂assets                            // Contains all the reference gifs, images
 ┣ 📂documentation                     // Contains documentation and my notes on transformers
 ┃ ┣ 📄README.md
 ┣ 📄model.py                          // Code for Transformer Architecture
 ┣ 📄train.py                          // Tokenizers
 ┣ 📄dataset.py                        // Datasets  
 ┣ 📄README.md
``` 

## References
* <a href="https://www.youtube.com/watch?v=ISNdQcPhsts&t=2729s">YouTube Video</a> by Umar Jamil on developing transformers from scratch.
* <a href="https://arxiv.org/abs/1706.03762">Link</a> to ```Attention is all you need``` paper explaining transformer architecture
* <a href="https://huggingface.co/datasets/opus_books">opus_books</a> dataset by huggingface
* Amirhossein Kazemnejad's Blog on <a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">Positional Encodings</a>
 
## License
[MIT License](https://opensource.org/licenses/MIT)